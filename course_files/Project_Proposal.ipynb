{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Comedy Animation Scripts Using Recurrent Neural Networks\n",
    "### Madison Karrh, Brent Perez, Samuel Remedios, Michael Schmidt, John Westbrooks\n",
    "### Team Pandemonium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling and text generation has been studied for decades, but more recently attempts to use deep learning and other machine learning techniques have been applied to these tasks.  However, more popular methods aim for building languages from the character-level upwards rather than from the word-level.  Even those that operate on a word-by-word basis (Markov chain modeling, n-gram models) usually do not incorporate parts-of-speech nor long-term memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we propose a method of tokenizing words alongside their parts-of-speech with unique identifiers for use in a recurrent neural network (RNN).  Specifically, we aim to generate text using the long short-term memory (LSTM) variant of the RNN using training data comprised of scripts from popular American cartoon television shows, such as the Simpsons, Family Guy, Rick and Morty, South Park, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate our model, we will first qualitatively inspect the generated scripts.  We will then measure the Levenshtein distance (or other similar metric) between the tokens and parts-of-speech of our training corpus and the generated scripts.  If the metric(s) is/are sensible, we will then compare our methods to already-existing text generation techniques such as character-level RNNs and Markov chain models to judge our model's efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to automatically generate text is two-fold.  First, if the results are reasonable, then it may be advantageous to further investigate how the language was modeled using this technique.  Second, the automatic generation of stories and scripts could potentially be used as a starting point for writers, or smooth the creation process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
