{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Comedy Animation Scripts Using Recurrent Neural Networks\n",
    "### Madison Karrh, Brent Perez, Samuel Remedios, Michael Schmidt, John Westbrooks\n",
    "### Team Pandemonium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling and text generation have been studied for decades, and more recently there have been attempts to use deep learning and other machine learning techniques for these tasks.  However, more popular methods aim for building languages from the character-level upwards rather than from the word-level.  Even those that operate on a word-by-word basis (Markov chain modeling, n-gram models) usually do not incorporate parts-of-speech nor long-term memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we propose a method of tokenizing words alongside their parts-of-speech with unique identifiers for use in a recurrent neural network (RNN).  Specifically, we aim to generate text using the long short-term memory (LSTM) variant of the RNN using training data comprised of scripts from popular American cartoon television shows, such as the Simpsons, Family Guy, Rick and Morty, South Park, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate our model, we will first qualitatively inspect the generated scripts as well as measure the Levenshtein distance between the tokens and parts-of-speech of our training corpus and the generated scripts.  If the Levenshtein metric is sensible, we will then compare our methods to already-existing text generation techniques such as character-level RNNs and Markov chain models to judge our model's efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to automatically generate text are two-fold.  First, if the results are reasonable, then it may be advantageous to investigate further how the language was modeled using this technique.  Second, automatic generation of stories and scripts could be useful as a starting point for writers, smoothing the creation process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
