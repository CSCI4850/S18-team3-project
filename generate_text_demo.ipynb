{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once training is complete and the model weights have been saved, we can generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                                           \n",
    "import sys                                                                                                   \n",
    "import os                                                                                                    \n",
    "import json                                                                                                  \n",
    "from tqdm import tqdm                                                                                        \n",
    "from keras.models import load_model                                                                          \n",
    "from keras.models import model_from_json                                                                     \n",
    "from keras import backend as K                                                                               \n",
    "import pickle     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x,y):\n",
    "    s = 0\n",
    "    z = x-y\n",
    "\n",
    "    for element in z:\n",
    "        s += element**2\n",
    "    return np.sqrt(s)\n",
    "\n",
    "def closest(dictionary, vec):\n",
    "    min_dist = 1000000000000\n",
    "    for key,val in dictionary.items():\n",
    "        v = np.array(val)[0]\n",
    "\n",
    "        d = dist(v, vec)\n",
    "\n",
    "        if d < min_dist:\n",
    "            min_dist = d\n",
    "            closest = key\n",
    "            closest_vec = val\n",
    "    return closest, np.array(closest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SET DIRECTORIES ##########\n",
    "DATA_DIR = os.path.join(\"data\", \"train\", \"cleaned\")\n",
    "MAPPING_FILE = os.path.join(\"utils\", \"mapping.pkl\")\n",
    "RNN_MODEL = os.path.join(\"models\", \"rnn_model_pos.hdf5\")\n",
    "\n",
    "INCLUDE_POS = True \n",
    "NUM_POS_TAGS = 47\n",
    "\n",
    "########## IMPORT DATA ##########\n",
    "with open(MAPPING_FILE, 'rb') as f:\n",
    "    mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOAD MODEL ##########\n",
    "model = load_model(RNN_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## INIT ##########\n",
    "\n",
    "# set up start token\n",
    "token = mapping['ST']\n",
    "token = np.array(token)\n",
    "token = np.reshape(token, (1,) + token.shape)\n",
    "\n",
    "if INCLUDE_POS:\n",
    "    final_shape = token.shape[-1] + NUM_POS_TAGS \n",
    "else:\n",
    "    final_shape = token.shape[-1]\n",
    "\n",
    "tmp = np.zeros(shape=(1,1,final_shape))\n",
    "tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "token = tmp\n",
    "noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "noise /= 10 #small amount of noise\n",
    "\n",
    "print(token.shape)\n",
    "print(noise.shape)\n",
    "\n",
    "en_count = 0\n",
    "\n",
    "words = []\n",
    "words.append('ST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERATE WORDS ##########\n",
    "\n",
    "print('ST', end=' ')\n",
    "\n",
    "while en_count <= 20:\n",
    "    out = model.predict([token, noise])\n",
    "\n",
    "    # snap the network's prediction to the closest real word, and also\n",
    "    # snap the network's prediction to the closest vector in our space\n",
    "    # so that it predicts with real words as previous values\n",
    "    closest_word, closest_vec = closest(mapping, out[0,0,:])\n",
    "    token = np.zeros(shape=out.shape)\n",
    "    token[0,0,:] = closest_vec\n",
    "\n",
    "    # fix shapes\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(out[0,0])] = out[0,0,:]\n",
    "    out = tmp\n",
    "\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "    token = tmp\n",
    "\n",
    "    noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "    noise /= 10\n",
    "\n",
    "    words.append(closest_word)\n",
    "    \n",
    "    if closest_word == \"EN\":\n",
    "        en_count += 1\n",
    "        print(closest_word)\n",
    "    else:\n",
    "        print(closest_word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## NO GRAMMAR VERSION ##########\n",
    "INCLUDE_POS = False\n",
    "RNN_MODEL = os.path.join(\"models\", \"rnn_model_no_pos.hdf5\")\n",
    "########## LOAD MODEL ##########\n",
    "model = load_model(RNN_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## INIT ##########\n",
    "\n",
    "# set up start token\n",
    "token = mapping['ST']\n",
    "token = np.array(token)\n",
    "token = np.reshape(token, (1,) + token.shape)\n",
    "\n",
    "if INCLUDE_POS:\n",
    "    final_shape = token.shape[-1] + NUM_POS_TAGS \n",
    "else:\n",
    "    final_shape = token.shape[-1]\n",
    "\n",
    "tmp = np.zeros(shape=(1,1,final_shape))\n",
    "tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "token = tmp\n",
    "noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "noise /= 10 #small amount of noise\n",
    "\n",
    "print(token.shape)\n",
    "print(noise.shape)\n",
    "\n",
    "en_count = 0\n",
    "\n",
    "words = []\n",
    "words.append('ST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERATE WORDS ##########\n",
    "\n",
    "print('ST', end=' ')\n",
    "\n",
    "while en_count <= 20:\n",
    "    out = model.predict([token, noise])\n",
    "\n",
    "    # snap the network's prediction to the closest real word, and also\n",
    "    # snap the network's prediction to the closest vector in our space\n",
    "    # so that it predicts with real words as previous values\n",
    "    closest_word, closest_vec = closest(mapping, out[0,0,:])\n",
    "    token = np.zeros(shape=out.shape)\n",
    "    token[0,0,:] = closest_vec\n",
    "\n",
    "    # fix shapes\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(out[0,0])] = out[0,0,:]\n",
    "    out = tmp\n",
    "\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "    token = tmp\n",
    "\n",
    "    noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "    noise /= 10\n",
    "\n",
    "    words.append(closest_word)\n",
    "    \n",
    "    if closest_word == \"EN\":\n",
    "        en_count += 1\n",
    "        print(closest_word)\n",
    "    else:\n",
    "        print(closest_word, end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
