{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Our goal is to determine whether text generated by the inclusion of grammatical structure is better than text generated without that grammatical structure.  Specifically, we want to know if adding part of speech vectors improves text generation.  To accomplish this, we will train two models with the same architecture over the same dataset, one with only words and one with parts of speech included.  The cells below will illustrate the results.\n",
    "\n",
    "Before running these cells, please read the instructions in README.md. In particular:\n",
    "\n",
    "1. acquire and preprocess data with `preprocess.py`\n",
    "1. adjust and train models with and without parts of speech with `train.py --include_pos`  y and `train.py --include_pos n`\n",
    "\n",
    "Once training is complete and the model weights have been saved, we can generate text as seen below.\n",
    "\n",
    "The following code will generate 20 \"sentences\" for each of the two models, where a sentence is considered complete simply as soon as the RNN decides to output the \"EN\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci4850/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                                                                           \n",
    "import sys                                                                                                   \n",
    "import os                                                                                                    \n",
    "import json                                                                                                  \n",
    "from tqdm import tqdm                                                                                        \n",
    "from keras.models import load_model                                                                          \n",
    "from keras.models import model_from_json                                                                     \n",
    "from keras import backend as K                                                                               \n",
    "import pickle     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITY FUNCTIONS ##########\n",
    "def dist(x,y):\n",
    "    s = 0\n",
    "    z = x-y\n",
    "\n",
    "    for element in z:\n",
    "        s += element**2\n",
    "    return np.sqrt(s)\n",
    "\n",
    "def closest(dictionary, vec):\n",
    "    min_dist = 1000000000000\n",
    "    for key,val in dictionary.items():\n",
    "        v = np.array(val)[0]\n",
    "\n",
    "        d = dist(v, vec)\n",
    "\n",
    "        if d < min_dist:\n",
    "            min_dist = d\n",
    "            closest = key\n",
    "            closest_vec = val\n",
    "    return closest, np.array(closest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SET DIRECTORIES ##########\n",
    "DATA_DIR = os.path.join(\"data\", \"train\", \"cleaned\")\n",
    "MAPPING_FILE = os.path.join(\"utils\", \"mapping.pkl\")\n",
    "RNN_MODEL_POS = os.path.join(\"models\", \"rnn_model_pos.hdf5\")\n",
    "RNN_MODEL_NO_POS = os.path.join(\"models\", \"rnn_model_no_pos.hdf5\")\n",
    "\n",
    "NUM_POS_TAGS = 47\n",
    "\n",
    "########## IMPORT DATA ##########\n",
    "with open(MAPPING_FILE, 'rb') as f:\n",
    "    mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOAD MODEL ##########\n",
    "\n",
    "########## NO GRAMMAR VERSION ##########\n",
    "model_no_pos = load_model(RNN_MODEL_NO_POS)\n",
    "\n",
    "########## GRAMMAR VERSION ##########\n",
    "model_pos = load_model(RNN_MODEL_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sentences without Part of Speech Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST EN\n",
      "pickle. ST EN\n",
      "pickle. a into myself ST EN\n",
      "and a i'm ST EN\n",
      "pickle. a into myself ST EN\n",
      "do i ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle. i'm ST EN\n",
      "pickle! a into myself ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle. ST EN\n",
      "house. ST EN\n",
      "pickle. ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle. ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle! a into myself ST EN\n",
      "pickle. i'm ST EN\n",
      "pickle. a into myself ST EN\n",
      "pickle. ST EN\n"
     ]
    }
   ],
   "source": [
    "########## NO GRAMMAR ##########\n",
    "INCLUDE_POS = False\n",
    "\n",
    "# set up start token\n",
    "token = mapping['ST']\n",
    "token = np.array(token)\n",
    "token = np.reshape(token, (1,) + token.shape)\n",
    "\n",
    "if INCLUDE_POS:\n",
    "    final_shape = token.shape[-1] + NUM_POS_TAGS \n",
    "else:\n",
    "    final_shape = token.shape[-1]\n",
    "\n",
    "tmp = np.zeros(shape=(1,1,final_shape))\n",
    "tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "token = tmp\n",
    "noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "noise /= 10 #small amount of noise\n",
    "\n",
    "en_count = 0\n",
    "\n",
    "words = []\n",
    "words.append('ST')\n",
    "\n",
    "########## GENERATE WORDS ##########\n",
    "\n",
    "print('ST', end=' ')\n",
    "\n",
    "while en_count <= 20:\n",
    "    out = model_no_pos.predict([token, noise])\n",
    "\n",
    "    # snap the network's prediction to the closest real word, and also\n",
    "    # snap the network's prediction to the closest vector in our space\n",
    "    # so that it predicts with real words as previous values\n",
    "    closest_word, closest_vec = closest(mapping, out[0,0,:])\n",
    "    token = np.zeros(shape=out.shape)\n",
    "    token[0,0,:] = closest_vec\n",
    "\n",
    "    # fix shapes\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(out[0,0])] = out[0,0,:]\n",
    "    out = tmp\n",
    "\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "    token = tmp\n",
    "\n",
    "    noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "    noise /= 10\n",
    "\n",
    "    words.append(closest_word)\n",
    "    \n",
    "    if closest_word == \"EN\":\n",
    "        en_count += 1\n",
    "        print(closest_word)\n",
    "    else:\n",
    "        print(closest_word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see here that the network fails to associate ST with the start of the sentence, and the sentences are quite short and repetitive.  Let's see how it does once the part of speech vectors are added!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sentences with Part of Speech Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST from it turns week who from it turns myself rick, don't science. heels] science. rick, don't i layers i-i'm which layers i-i'm which mind. [beth which from it did [beth from it did from it ooh, all EN\n",
      "from it ooh, all -- rick: EN\n",
      "from it ooh, all -- rick: mean, who from it boom! that's stop stop terrorism which stop about dark which mind. dark i-i'm which layers science. science. layers which stop about all -- -- family sweetie. which mind. [beth from it oh, all EN\n",
      "from it did [beth think think sweetie. layers science. rick, don't science. rick, don't science. science. rick, stop enter dark and [beth from it this layers that's stop about dark sweetie. which mind. [beth from it oh, all -- rick: mean, who from it turns magic i-i'm who beth: which mind. [beth from it did [beth from it pickle, all EN\n",
      "from it turns week who from it ooh, and [beth from it oh, can, from it for, layers myself rick, stop my EN\n",
      "from it turns myself layers which layers myself rick, don't i rick, don't science. science. science. science. rick, who from it did from it for who from it did [beth from it oh, all -- rick: who and [beth from it ooh, from it did [beth who from it did [beth from it oh, all EN\n",
      "from it for, can, from it pickle, all -- rick: mean, EN\n",
      "from it ooh, all -- rick: EN\n",
      "from it did [beth think who from it oh, all -- rick: mean, who from it did [beth who from it oh, dark sweetie. layers that's stop stop about all EN\n",
      "from it oh, which stop from it did from it did [beth from it ooh, all -- rick: EN\n",
      "from it pickles sweetie. layers science. science. rick, garage a layers myself science. layers i layers myself rick, don't science. science. rick, layers which upon from it ooh, all -- rick: who and [beth think and [beth who from it pickle, all -- rick: who from it did from it ooh, all EN\n",
      "from it the which mind. dark all -- rick: mean, who from it this all -- rick: mean, who from it did [beth who from it oh, sweetie. is which brains, never layers i-i'm EN\n",
      "from it the which mind. [beth from it turns week never all -- rick: who from it oh, and [beth from it this layers science. science. science. don't science. rick, which upon from it did [beth think don't science. science. rick, stop from it oh, dark sweetie. layers layers which mind. [beth which upon from it did [beth think sweetie. staring stop from it for, which upon from it did [beth which mind. dark by dark sweetie. -- rick: mean, who from it ooh, all -- rick: mean, i-i'm sweetie. is which layers science. rick, which stop about all EN\n",
      "from it did [beth think sweetie. is which counseling? stop about all -- rick: EN\n",
      "from it this can, from it ooh, all -- rick: who beth: who and [beth who from it boom! can, all EN\n",
      "from it did from it did [beth from it did [beth think sweetie. move? from it ooh, all -- rick: mean, who and [beth think from it ooh, which slipped which upon who from it oh, all EN\n",
      "from it oh, can, from it ooh, all -- rick: mean, who and [beth from it pickle, which layers which mind. dark sweetie. which slipped stop other stop from it ooh, and [beth from it ooh, all -- rick: who from it oh, all EN\n",
      "from it did [beth from it for, and [beth from it at has about all EN\n",
      "from it pickle, which mind. all -- rick: EN\n",
      "from it ooh, from it pickle, stop from it at has part which layers which mind. [beth from it did [beth from it ooh, all -- rick: mean, who and [beth from it did [beth from it ooh, dark all EN\n",
      "from it ooh, all -- rick: who and [beth from it did [beth think who and [beth from it ooh, all EN\n"
     ]
    }
   ],
   "source": [
    "########## GRAMMAR ##########\n",
    "INCLUDE_POS = True \n",
    "\n",
    "# set up start token\n",
    "token = mapping['ST']\n",
    "token = np.array(token)\n",
    "token = np.reshape(token, (1,) + token.shape)\n",
    "\n",
    "if INCLUDE_POS:\n",
    "    final_shape = token.shape[-1] + NUM_POS_TAGS \n",
    "else:\n",
    "    final_shape = token.shape[-1]\n",
    "\n",
    "tmp = np.zeros(shape=(1,1,final_shape))\n",
    "tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "token = tmp\n",
    "noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "noise /= 10 #small amount of noise\n",
    "\n",
    "en_count = 0\n",
    "\n",
    "words = []\n",
    "words.append('ST')\n",
    "\n",
    "########## GENERATE WORDS ##########\n",
    "\n",
    "print('ST', end=' ')\n",
    "\n",
    "while en_count <= 20:\n",
    "    out = model_pos.predict([token, noise])\n",
    "\n",
    "    # snap the network's prediction to the closest real word, and also\n",
    "    # snap the network's prediction to the closest vector in our space\n",
    "    # so that it predicts with real words as previous values\n",
    "    closest_word, closest_vec = closest(mapping, out[0,0,:])\n",
    "    token = np.zeros(shape=out.shape)\n",
    "    token[0,0,:] = closest_vec\n",
    "\n",
    "    # fix shapes\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(out[0,0])] = out[0,0,:]\n",
    "    out = tmp\n",
    "\n",
    "    tmp = np.zeros(shape=(1,1,final_shape))\n",
    "    tmp[0,0,:len(token[0,0])] = token[0,0,:]\n",
    "    token = tmp\n",
    "\n",
    "    noise = np.random.rand(token.shape[0], token.shape[1], token.shape[2])\n",
    "    noise /= 10\n",
    "\n",
    "    words.append(closest_word)\n",
    "    \n",
    "    if closest_word == \"EN\":\n",
    "        en_count += 1\n",
    "        print(closest_word)\n",
    "    else:\n",
    "        print(closest_word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Overall, the results from the inclusion of the parts of speech seem to be better, but only in length and variety.  This time the ST token is entirely absent (except for the initial seed) and sentences all begin with \"from it\".  Of course, these sentences are also not comprehensible nor cohesive.  We believe with less naive encoding, a more fleshed-out architecture, and possibly a better means of diversity that the RNN would be able to make significantly better-structured sentences with grammatical context present."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
